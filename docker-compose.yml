# Racing Post Scraper
#
# Triggered by deploy.sh via cron (not run continuously)
#
# Usage:
#   ./deploy.sh                              # Full deploy: git pull, build, run
#   docker compose run --rm scraper          # Run both jobs (racecards + results)
#   docker compose run --rm scraper racecards # Racecards only
#   docker compose run --rm scraper results   # Results only
#
# Crontab (on NAS host):
#   0 6 * * * /path/to/racing_post_scraper/deploy.sh

services:
  scraper:
    build: .
    container_name: racing-post-scraper

    environment:
      # API endpoint (nas_api_003 Django server)
      - API_URL=${API_URL:-http://host.docker.internal:8000/api/racing-post}
      - REGIONS=${REGIONS:-gb,ire}
      - TZ=UTC

      # Racing Post credentials
      - EMAIL=${EMAIL}
      - AUTH_STATE=${AUTH_STATE}
      - ACCESS_TOKEN=${ACCESS_TOKEN}

    # Allow access to host network (to reach nas_api_003)
    extra_hosts:
      - "host.docker.internal:host-gateway"

    volumes:
      # Logs (standardised structure)
      - ./logs:/app/logs
      # Error logs (persistent for debugging)
      - ./error_logs:/app/error_logs

    # Resource limits
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 128M

    # Healthcheck
    healthcheck:
      test: ["CMD", "pgrep", "-f", "docker-entrypoint"]
      interval: 60s
      timeout: 10s
      start_period: 30s
      retries: 3
